{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhOkVLpoREDU"
      },
      "source": [
        "# 1 reading data and preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LoQwtEwnRIjm",
        "outputId": "d33c0c97-288c-46ab-fadc-6d18aab9ef01",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pickle as pk\n",
        "import tensorflow as tf\n",
        "from transformers import BertTokenizerFast, TFBertModel\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "def load_dataset(file_path):\n",
        "    with open(file_path, 'rb') as file:\n",
        "        return pk.load(file)\n",
        "\n",
        "train_data = load_dataset('/content/drive/MyDrive/hw6_nlp/train.pickle')\n",
        "val_data = load_dataset('/content/drive/MyDrive/hw6_nlp/validation.pickle')\n",
        "test_data = load_dataset('/content/drive/MyDrive/hw6_nlp/test.pickle')\n",
        "\n",
        "#create label mappings\n",
        "def generate_label_maps(tags_list):\n",
        "    unique_tags = set(tag for tags in tags_list for tag in tags)\n",
        "    tag_to_id = {tag: idx for idx, tag in enumerate(unique_tags)}\n",
        "    id_to_tag = {idx: tag for tag, idx in tag_to_id.items()}\n",
        "    return tag_to_id, id_to_tag\n",
        "\n",
        "ner_tag_to_id, ner_id_to_tag = generate_label_maps(train_data[\"ner_tags\"])\n",
        "pos_tag_to_id, pos_id_to_tag = generate_label_maps(train_data[\"pos_tags\"])\n",
        "\n",
        "num_ner_classes = len(ner_tag_to_id)\n",
        "num_pos_classes = len(pos_tag_to_id)\n",
        "\n",
        "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-cased\")\n",
        "\n",
        "# data preparation\n",
        "def tag_mapper(tags, idx, word_ids, tag_map):\n",
        "    tag_sequence = []\n",
        "    last_word_id = None\n",
        "    for word_id in word_ids:\n",
        "        if word_id is None or word_id == last_word_id or word_id >= len(tags[idx]):\n",
        "            tag_sequence.append(-100)\n",
        "        else:\n",
        "            last_word_id = word_id\n",
        "            tag_sequence.append(tag_map[tags[idx][word_id]])\n",
        "    return tag_sequence\n",
        "\n",
        "def create_data_generator(data, tags_ner, tags_pos, batch_size=32):\n",
        "    def generator():\n",
        "        for idxs in np.array_split(np.arange(len(data[\"tokens\"])), np.ceil(len(data[\"tokens\"]) / batch_size)):\n",
        "            tokenized_inputs = tokenizer(\n",
        "                [\" \".join(tokens) for tokens in data[\"tokens\"][idxs]],\n",
        "                add_special_tokens=True,\n",
        "                return_tensors=\"tf\",\n",
        "                truncation=True,\n",
        "                padding=\"max_length\",\n",
        "                max_length=128\n",
        "            )\n",
        "            ner_labels = [tag_mapper(tags_ner, idx, tokenized_inputs.word_ids(batch_index=i), ner_tag_to_id) for i, idx in enumerate(idxs)]\n",
        "            pos_labels = [tag_mapper(tags_pos, idx, tokenized_inputs.word_ids(batch_index=i), pos_tag_to_id) for i, idx in enumerate(idxs)]\n",
        "            yield dict(tokenized_inputs), (tf.constant(ner_labels), tf.constant(pos_labels))\n",
        "    return generator\n",
        "\n",
        "train_gen = create_data_generator(train_data, train_data[\"ner_tags\"], train_data[\"pos_tags\"])\n",
        "val_gen = create_data_generator(val_data, val_data[\"ner_tags\"], val_data[\"pos_tags\"])\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_generator(train_gen, output_signature=(\n",
        "    {\n",
        "        \"input_ids\": tf.TensorSpec(shape=(None, 128), dtype=tf.int32),\n",
        "        \"token_type_ids\": tf.TensorSpec(shape=(None, 128), dtype=tf.int32),\n",
        "        \"attention_mask\": tf.TensorSpec(shape=(None, 128), dtype=tf.int32),\n",
        "    },\n",
        "    (\n",
        "        tf.TensorSpec(shape=(None, 128), dtype=tf.int32),\n",
        "        tf.TensorSpec(shape=(None, 128), dtype=tf.int32)\n",
        "    )\n",
        "))\n",
        "\n",
        "val_dataset = tf.data.Dataset.from_generator(val_gen, output_signature=(\n",
        "    {\n",
        "        \"input_ids\": tf.TensorSpec(shape=(None, 128), dtype=tf.int32),\n",
        "        \"token_type_ids\": tf.TensorSpec(shape=(None, 128), dtype=tf.int32),\n",
        "        \"attention_mask\": tf.TensorSpec(shape=(None, 128), dtype=tf.int32),\n",
        "    },\n",
        "    (\n",
        "        tf.TensorSpec(shape=(None, 128), dtype=tf.int32),\n",
        "        tf.TensorSpec(shape=(None, 128), dtype=tf.int32)\n",
        "    )\n",
        "))\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "SNuHyB8lRJ5c"
      },
      "source": [
        "# 2 making the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7SNUkHv7RXlF",
        "outputId": "7038313b-9bce-473b-85e7-1b401d44aa9e",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFBertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " attention_mask (InputLayer  [(None, 128)]                0         []                            \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " input_ids (InputLayer)      [(None, 128)]                0         []                            \n",
            "                                                                                                  \n",
            " token_type_ids (InputLayer  [(None, 128)]                0         []                            \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " bert_encoder (BERTEncoder)  (None, 128, 768)             1083102   ['attention_mask[0][0]',      \n",
            "                                                          72         'input_ids[0][0]',           \n",
            "                                                                     'token_type_ids[0][0]']      \n",
            "                                                                                                  \n",
            " dropout_37 (Dropout)        (None, 128, 768)             0         ['bert_encoder[0][0]']        \n",
            "                                                                                                  \n",
            " dropout_39 (Dropout)        (None, 128, 768)             0         ['bert_encoder[0][0]']        \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 128, 256)             196864    ['dropout_37[0][0]']          \n",
            "                                                                                                  \n",
            " dense_1 (Dense)             (None, 128, 256)             196864    ['dropout_39[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_38 (Dropout)        (None, 128, 256)             0         ['dense[0][0]']               \n",
            "                                                                                                  \n",
            " dropout_40 (Dropout)        (None, 128, 256)             0         ['dense_1[0][0]']             \n",
            "                                                                                                  \n",
            " ner_output (Dense)          (None, 128, 9)               2313      ['dropout_38[0][0]']          \n",
            "                                                                                                  \n",
            " pos_output (Dense)          (None, 128, 45)              11565     ['dropout_40[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 108717878 (414.73 MB)\n",
            "Trainable params: 108717878 (414.73 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "input_ids = tf.keras.Input(shape=(128,), dtype=tf.int32, name=\"input_ids\")\n",
        "token_type_ids = tf.keras.Input(shape=(128,), dtype=tf.int32, name=\"token_type_ids\")\n",
        "attention_mask = tf.keras.Input(shape=(128,), dtype=tf.int32, name=\"attention_mask\")\n",
        "\n",
        "class BERTEncoder(tf.keras.layers.Layer):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.model = TFBertModel.from_pretrained(\"bert-base-cased\", trainable=True)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return self.model(inputs)[0]\n",
        "\n",
        "bert_output = BERTEncoder()({\n",
        "    \"input_ids\": input_ids,\n",
        "    \"token_type_ids\": token_type_ids,\n",
        "    \"attention_mask\": attention_mask\n",
        "})\n",
        "\n",
        "# define output layers for NER and POS\n",
        "def create_classification_layer(bert_output, name, num_classes):\n",
        "    x = tf.keras.layers.Dropout(0.3)(bert_output)\n",
        "    x = tf.keras.layers.Dense(256, activation=\"relu\")(x)\n",
        "    x = tf.keras.layers.Dropout(0.1)(x)\n",
        "    return tf.keras.layers.Dense(num_classes, activation=\"softmax\", name=name)(x)\n",
        "\n",
        "ner_output = create_classification_layer(bert_output, \"ner_output\", num_ner_classes)\n",
        "pos_output = create_classification_layer(bert_output, \"pos_output\", num_pos_classes)\n",
        "\n",
        "model = tf.keras.Model(inputs=[input_ids, token_type_ids, attention_mask], outputs=[ner_output, pos_output])\n",
        "\n",
        "def masked_accuracy(y_true, y_pred):\n",
        "    mask = tf.not_equal(y_true, -100)\n",
        "    y_true_masked = tf.boolean_mask(y_true, mask)\n",
        "    y_pred_masked = tf.boolean_mask(y_pred, mask)\n",
        "    return tf.reduce_mean(tf.keras.metrics.sparse_categorical_accuracy(y_true_masked, y_pred_masked))\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
        "    loss={\n",
        "        \"ner_output\": tf.keras.losses.SparseCategoricalCrossentropy(ignore_class=-100),\n",
        "        \"pos_output\": tf.keras.losses.SparseCategoricalCrossentropy(ignore_class=-100),\n",
        "    },\n",
        "    metrics={\n",
        "        \"ner_output\": [masked_accuracy],\n",
        "        \"pos_output\": [masked_accuracy],\n",
        "    }\n",
        ")\n",
        "\n",
        "model.summary()\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "KBdL8HllRa2A"
      },
      "source": [
        "# 3 training the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vkY24pSQReiq",
        "outputId": "7a30cd42-4a4d-4df3-8b05-a5e271b62c53",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "439/439 [==============================] - 461s 883ms/step - loss: 1.2651 - ner_output_loss: 0.2534 - pos_output_loss: 1.0117 - ner_output_masked_accuracy: 0.9287 - pos_output_masked_accuracy: 0.7339 - val_loss: 0.6503 - val_ner_output_loss: 0.1302 - val_pos_output_loss: 0.5201 - val_ner_output_masked_accuracy: 0.9597 - val_pos_output_masked_accuracy: 0.8480\n",
            "Epoch 2/5\n",
            "439/439 [==============================] - 381s 868ms/step - loss: 0.5739 - ner_output_loss: 0.1099 - pos_output_loss: 0.4640 - ner_output_masked_accuracy: 0.9664 - pos_output_masked_accuracy: 0.8635 - val_loss: 0.4976 - val_ner_output_loss: 0.1055 - val_pos_output_loss: 0.3922 - val_ner_output_masked_accuracy: 0.9688 - val_pos_output_masked_accuracy: 0.8838\n",
            "Epoch 3/5\n",
            "439/439 [==============================] - 381s 868ms/step - loss: 0.4233 - ner_output_loss: 0.0787 - pos_output_loss: 0.3446 - ner_output_masked_accuracy: 0.9750 - pos_output_masked_accuracy: 0.8949 - val_loss: 0.4455 - val_ner_output_loss: 0.0967 - val_pos_output_loss: 0.3488 - val_ner_output_masked_accuracy: 0.9739 - val_pos_output_masked_accuracy: 0.8999\n",
            "Epoch 4/5\n",
            "439/439 [==============================] - 381s 868ms/step - loss: 0.3350 - ner_output_loss: 0.0595 - pos_output_loss: 0.2755 - ner_output_masked_accuracy: 0.9803 - pos_output_masked_accuracy: 0.9132 - val_loss: 0.4289 - val_ner_output_loss: 0.0914 - val_pos_output_loss: 0.3375 - val_ner_output_masked_accuracy: 0.9751 - val_pos_output_masked_accuracy: 0.9037\n",
            "Epoch 5/5\n",
            "439/439 [==============================] - 392s 894ms/step - loss: 0.2893 - ner_output_loss: 0.0530 - pos_output_loss: 0.2363 - ner_output_masked_accuracy: 0.9826 - pos_output_masked_accuracy: 0.9257 - val_loss: 0.4662 - val_ner_output_loss: 0.1078 - val_pos_output_loss: 0.3584 - val_ner_output_masked_accuracy: 0.9717 - val_pos_output_masked_accuracy: 0.9031\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "439/439 [==============================] - 455s 902ms/step - loss: 0.1977 - ner_output_loss: 0.0341 - pos_output_loss: 0.1635 - ner_output_masked_accuracy: 0.9885 - pos_output_masked_accuracy: 0.9466 - val_loss: 0.3944 - val_ner_output_loss: 0.0864 - val_pos_output_loss: 0.3080 - val_ner_output_masked_accuracy: 0.9802 - val_pos_output_masked_accuracy: 0.9245\n",
            "Epoch 2/5\n",
            "439/439 [==============================] - 381s 867ms/step - loss: 0.1457 - ner_output_loss: 0.0238 - pos_output_loss: 0.1219 - ner_output_masked_accuracy: 0.9914 - pos_output_masked_accuracy: 0.9589 - val_loss: 0.4114 - val_ner_output_loss: 0.0912 - val_pos_output_loss: 0.3202 - val_ner_output_masked_accuracy: 0.9809 - val_pos_output_masked_accuracy: 0.9268\n",
            "Epoch 3/5\n",
            "439/439 [==============================] - 381s 867ms/step - loss: 0.1200 - ner_output_loss: 0.0185 - pos_output_loss: 0.1015 - ner_output_masked_accuracy: 0.9933 - pos_output_masked_accuracy: 0.9653 - val_loss: 0.4159 - val_ner_output_loss: 0.0893 - val_pos_output_loss: 0.3267 - val_ner_output_masked_accuracy: 0.9814 - val_pos_output_masked_accuracy: 0.9298\n",
            "Epoch 4/5\n",
            "439/439 [==============================] - 380s 867ms/step - loss: 0.1027 - ner_output_loss: 0.0160 - pos_output_loss: 0.0867 - ner_output_masked_accuracy: 0.9940 - pos_output_masked_accuracy: 0.9705 - val_loss: 0.4297 - val_ner_output_loss: 0.0953 - val_pos_output_loss: 0.3345 - val_ner_output_masked_accuracy: 0.9817 - val_pos_output_masked_accuracy: 0.9298\n",
            "Epoch 5/5\n",
            "439/439 [==============================] - 380s 866ms/step - loss: 0.0916 - ner_output_loss: 0.0148 - pos_output_loss: 0.0768 - ner_output_masked_accuracy: 0.9946 - pos_output_masked_accuracy: 0.9737 - val_loss: 0.4509 - val_ner_output_loss: 0.0970 - val_pos_output_loss: 0.3539 - val_ner_output_masked_accuracy: 0.9818 - val_pos_output_masked_accuracy: 0.9307\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# freeze BERT layers and train only the new layers\n",
        "model.get_layer('bert_encoder').trainable = False\n",
        "initial_training_history = model.fit(train_dataset, validation_data=val_dataset, epochs=5)\n",
        "\n",
        "# unfreeze the entire model and train again\n",
        "model.get_layer('bert_encoder').trainable = True\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=2e-5),\n",
        "    loss={\n",
        "        \"ner_output\": tf.keras.losses.SparseCategoricalCrossentropy(ignore_class=-100),\n",
        "        \"pos_output\": tf.keras.losses.SparseCategoricalCrossentropy(ignore_class=-100),\n",
        "    },\n",
        "    metrics={\n",
        "        \"ner_output\": [masked_accuracy],\n",
        "        \"pos_output\": [masked_accuracy],\n",
        "    }\n",
        ")\n",
        "final_training_history = model.fit(train_dataset, validation_data=val_dataset, epochs=5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHxRT5zgc7De",
        "outputId": "938c6313-da78-4a50-a08c-81d83210a588",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 9s 9s/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 283ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 294ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 295ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 254ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 138ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 294ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 140ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 291ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 133ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 117ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 66ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 77ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 201ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 264ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 219ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 287ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 235ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 10s 10s/step\n",
            "1/1 [==============================] - 0s 277ms/step\n",
            "1/1 [==============================] - 0s 278ms/step\n",
            "1/1 [==============================] - 0s 277ms/step\n",
            "1/1 [==============================] - 0s 276ms/step\n",
            "1/1 [==============================] - 0s 278ms/step\n",
            "1/1 [==============================] - 0s 276ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 111ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 112ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 159ms/step\n",
            "1/1 [==============================] - 0s 158ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 127ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 286ms/step\n",
            "1/1 [==============================] - 0s 282ms/step\n",
            "1/1 [==============================] - 0s 284ms/step\n",
            "1/1 [==============================] - 0s 281ms/step\n",
            "1/1 [==============================] - 0s 281ms/step\n",
            "1/1 [==============================] - 0s 288ms/step\n",
            "1/1 [==============================] - 0s 284ms/step\n",
            "1/1 [==============================] - 0s 292ms/step\n",
            "1/1 [==============================] - 0s 283ms/step\n",
            "1/1 [==============================] - 0s 283ms/step\n",
            "1/1 [==============================] - 0s 280ms/step\n",
            "1/1 [==============================] - 0s 282ms/step\n",
            "1/1 [==============================] - 0s 283ms/step\n",
            "1/1 [==============================] - 0s 285ms/step\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "tf.get_logger().setLevel('ERROR')\n",
        "# Flatten utility function\n",
        "def flatten(l):\n",
        "    return [item for sublist in l for item in sublist]\n",
        "\n",
        "def calculate_macro_accuracy(dataset):\n",
        "    true_ner = []\n",
        "    true_pos = []\n",
        "    pred_ner = []\n",
        "    pred_pos = []\n",
        "\n",
        "    for inputs, labels in dataset:\n",
        "        outputs = model.predict(inputs)\n",
        "        ner_preds = np.argmax(outputs[0], axis=-1)\n",
        "        pos_preds = np.argmax(outputs[1], axis=-1)\n",
        "\n",
        "        for i, label in enumerate(labels[0]):\n",
        "            true_label_ner = label.numpy()\n",
        "            true_label_pos = labels[1][i].numpy()\n",
        "            pred_label_ner = ner_preds[i]\n",
        "            pred_label_pos = pos_preds[i]\n",
        "\n",
        "            mask = true_label_ner != -100\n",
        "            true_ner.extend(true_label_ner[mask])\n",
        "            pred_ner.extend(pred_label_ner[mask])\n",
        "\n",
        "            mask = true_label_pos != -100\n",
        "            true_pos.extend(true_label_pos[mask])\n",
        "            pred_pos.extend(pred_label_pos[mask])\n",
        "\n",
        "    ner_accuracy = accuracy_score(true_ner, pred_ner)\n",
        "    pos_accuracy = accuracy_score(true_pos, pred_pos)\n",
        "\n",
        "    return ner_accuracy, pos_accuracy\n",
        "\n",
        "ner_train_acc, pos_train_acc = calculate_macro_accuracy(train_dataset)\n",
        "ner_val_acc, pos_val_acc = calculate_macro_accuracy(val_dataset)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "defPZP_PfLNU",
        "outputId": "0dee25b4-2e0e-4af5-cc68-f90e0fb8cf1d",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train NER Macro Accuracy: 0.9973690119395117\n",
            "Train POS Macro Accuracy: 0.9868352972186698\n",
            "Validation NER Macro Accuracy: 0.9816469299169792\n",
            "Validation POS Macro Accuracy: 0.9301909056428842\n"
          ]
        }
      ],
      "source": [
        "print(f\"Train NER Macro Accuracy: {ner_train_acc}\")\n",
        "print(f\"Train POS Macro Accuracy: {pos_train_acc}\")\n",
        "print(f\"Validation NER Macro Accuracy: {ner_val_acc}\")\n",
        "print(f\"Validation POS Macro Accuracy: {pos_val_acc}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "8fhnRc_bR9jT"
      },
      "source": [
        "# 4 predicting on test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wy1yi6YySANH",
        "outputId": "e21ed7f7-e67d-492b-bf77-e2c777f6c467",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 110ms/step\n",
            "1/1 [==============================] - 0s 128ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 155ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 74ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 136ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 282ms/step\n",
            "1/1 [==============================] - 0s 287ms/step\n",
            "1/1 [==============================] - 0s 285ms/step\n",
            "Length of NER predictions: 3453\n",
            "Length of POS predictions: 3453\n"
          ]
        }
      ],
      "source": [
        "tf.get_logger().setLevel('ERROR')\n",
        "def test_data_generator(batch_size=32):\n",
        "    def generator():\n",
        "        for idxs in np.array_split(np.arange(len(test_data[\"tokens\"])), np.ceil(len(test_data[\"tokens\"]) / batch_size)):\n",
        "            tokenized_inputs = tokenizer(\n",
        "                [\" \".join(tokens) for tokens in test_data[\"tokens\"][idxs]],\n",
        "                add_special_tokens=True,\n",
        "                return_tensors=\"tf\",\n",
        "                truncation=True,\n",
        "                padding=\"max_length\",\n",
        "                max_length=128\n",
        "            )\n",
        "            yield dict(tokenized_inputs)\n",
        "    return generator\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_generator(test_data_generator(), output_signature={\n",
        "    \"input_ids\": tf.TensorSpec(shape=(None, 128), dtype=tf.int32),\n",
        "    \"token_type_ids\": tf.TensorSpec(shape=(None, 128), dtype=tf.int32),\n",
        "    \"attention_mask\": tf.TensorSpec(shape=(None, 128), dtype=tf.int32)\n",
        "})\n",
        "\n",
        "test_predictions = {\"tokens\": [], \"ner_preds\": [], \"pos_preds\": []}\n",
        "\n",
        "for batch in test_dataset:\n",
        "    inputs = {key: val for key, val in batch.items()}\n",
        "    outputs = model.predict(inputs)\n",
        "\n",
        "    ner_preds = np.argmax(outputs[0], axis=-1)\n",
        "    pos_preds = np.argmax(outputs[1], axis=-1)\n",
        "\n",
        "    for i in range(len(inputs[\"input_ids\"])):\n",
        "        tokens = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][i].numpy())\n",
        "        ner_tags = ner_preds[i].tolist()\n",
        "        pos_tags = pos_preds[i].tolist()\n",
        "\n",
        "        test_predictions[\"tokens\"].append(tokens)\n",
        "        test_predictions[\"ner_preds\"].append(ner_tags)\n",
        "        test_predictions[\"pos_preds\"].append(pos_tags)\n",
        "\n",
        "with open('/content/drive/MyDrive/hw6_nlp/test_predictions.pickle', 'wb') as file:\n",
        "    pk.dump(test_predictions, file)\n",
        "\n",
        "with open('/content/drive/MyDrive/hw6_nlp/test_predictions.pickle', 'rb') as file:\n",
        "    loaded_predictions = pk.load(file)\n",
        "\n",
        "print(\"Length of NER predictions:\", len(loaded_predictions['ner_preds']))\n",
        "print(\"Length of POS predictions:\", len(loaded_predictions['pos_preds']))\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "name": "Welcome To Colab",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
